{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e92f9fb",
   "metadata": {},
   "source": [
    "# Building a RAG (Retrieval Augmented Generation) Application\n",
    "\n",
    "This notebook demonstrates how to build a Retrieval Augmented Generation (RAG) system for question answering over text data sources. We'll use LangChain, LangGraph, and other libraries to create a simple but powerful RAG application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b924cf",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, let's set up the environment variables for LangSmith tracing and API keys for required services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba67b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set TOKENIZERS_PARALLELISM to False to avoid deadlocks and warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Setup LangSmith for tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG Application\"\n",
    "\n",
    "# Verify OpenAI API key is available\n",
    "assert os.getenv(\"GROQ_API_KEY\"), \"OpenAI API key not found in environment variables\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66facd4f",
   "metadata": {},
   "source": [
    "## 2. Install Required Libraries\n",
    "\n",
    "Install all necessary libraries, including langchain, langgraph, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ebc446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (0.3.11)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.12/site-packages (0.3.12)\n",
      "Requirement already satisfied: langgraph in /opt/anaconda3/lib/python3.12/site-packages (0.3.30)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/lib/python3.12/site-packages (0.5.23)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.2.3)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-openai) (1.74.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph) (2.0.24)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph) (0.1.61)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.115.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (3.7.4)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (1.67.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (3.10.12)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/anaconda3/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/anaconda3/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.37.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.12/site-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.26.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.3)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this cell to install required packages\n",
    "%pip install langchain langchain-openai langgraph chromadb beautifulsoup4 tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163f298",
   "metadata": {},
   "source": [
    "## 3. Load and Chunk Data\n",
    "\n",
    "We'll use WebBaseLoader to load blog post content and RecursiveCharacterTextSplitter to split it into manageable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457c6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./final_review.pdf\")\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2fb2d",
   "metadata": {},
   "source": [
    "## 4. Index Data\n",
    "\n",
    "Embed the document chunks using an embeddings model and store them in a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7ee4685e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VectorStore.from_documents() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m unique_collection_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag-blog-post-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex[:\u001b[38;5;241m8\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Create vector store from documents\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m InMemoryVectorStore\u001b[38;5;241m.\u001b[39mfrom_documents(pages, embeddings, unique_collection_name)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=600)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# all_splits = text_splitter.split_documents(pages)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Index chunks\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# _ = vector_store.add_documents(documents=all_splits)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem statement\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: VectorStore.from_documents() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize embeddings model\n",
    "# all-mpnet-base-v2 produces 768-dimensional embeddings to match existing collection\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"thenlper/gte-large\",  # This model produces 768-dimensional vectors\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True, \"batch_size\": 16}\n",
    ")\n",
    "\n",
    "# Create vector store from documents\n",
    "vector_store = InMemoryVectorStore.from_documents(pages, embeddings)\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=600)\n",
    "# all_splits = text_splitter.split_documents(pages)\n",
    "\n",
    "# Index chunks\n",
    "# _ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "docs = vector_store.similarity_search(\"Problem statement\", k=4)\n",
    "for doc in docs:\n",
    "    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[0:]}\\n')\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985046a3",
   "metadata": {},
   "source": [
    "## 5. Define Application State\n",
    "\n",
    "Define a TypedDict to represent the state of the application, including question, context, and answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3ca7459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class RAGState(TypedDict):\n",
    "    \"\"\"State for the RAG application.\"\"\"\n",
    "    question: str\n",
    "    retrieved_documents: Optional[List[Document]]\n",
    "    context: Optional[str]\n",
    "    answer: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f9422",
   "metadata": {},
   "source": [
    "## 6. Implement Retrieval and Generation Steps\n",
    "\n",
    "Define the retrieval step to search for relevant documents and the generation step to produce answers using a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "508b3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def retrieve(state: RAGState):\n",
    "    \"\"\"Retrieve relevant documents based on the question.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    sorted_results = sorted(\n",
    "        retrieved_docs,\n",
    "        key=lambda doc: doc.metadata.get('page', float('inf')) # Use .get() with a default for safety\n",
    "    )\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in sorted_results])\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"context\": context,\n",
    "        \"answer\": None\n",
    "    }\n",
    "\n",
    "def generate_answer(state: RAGState):\n",
    "    \"\"\"Generate an answer based on the question and retrieved context.\"\"\"\n",
    "    # Initialize Groq LLM\n",
    "    llm = ChatGroq(\n",
    "        model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",  # Using Llama 3.3 for better reasoning\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        temperature=0.2  # Lower temperature for more factual responses\n",
    "    )\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    You are a helpful AI assistant that answers questions based on the provided context.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question:\n",
    "    {question}\n",
    "    \n",
    "    Answer the question based only on the provided context. Be concise, accurate, and helpful.\n",
    "    If the answer cannot be determined from the context, say so.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = llm.invoke(\n",
    "        prompt.format(\n",
    "            context=state[\"context\"],\n",
    "            question=state[\"question\"]\n",
    "        )\n",
    "    ).content\n",
    "    \n",
    "    return {\n",
    "        \"question\": state[\"question\"],\n",
    "        \"retrieved_documents\": state[\"retrieved_documents\"],\n",
    "        \"context\": state[\"context\"],\n",
    "        \"answer\": answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539cb3a",
   "metadata": {},
   "source": [
    "## 7. Build and Compile Application Graph\n",
    "\n",
    "Use LangGraph to define the control flow of the application and compile it into a graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d9d7d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# Create a new graph\n",
    "graph_builder = StateGraph(RAGState).add_sequence([retrieve, generate_answer])\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "\n",
    "# Compile the graph\n",
    "rag_app = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877662e",
   "metadata": {},
   "source": [
    "## 8. Test Application\n",
    "\n",
    "Invoke the application with a sample question and display the retrieved context and generated answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "220605e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Processing Module\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Retrieved Context (sample):\n",
      "3. Domain : \n",
      "The domain of the Price Pulse project encompasses a broad spectrum of e-commerce, consumer \n",
      "technology, price optimization tools, and web application development, each contributing to the project's \n",
      "mission of simplifying the online shopping experience for users. \n",
      "E-commerce \n",
      "E-commerce is the backbone of online retail, where consumers access digital marketplaces to purchase goods \n",
      "and services. These platforms feature dynamic pricing, influenced by factors such as demand, competition, \n",
      "and promotions, which often result in fluctuating prices. In this environment, consumers face the challenge \n",
      "of monitoring prices across various platforms and taking advantage of the best deals in real-time. Price Pulse \n",
      "addresses this issue by focusing on real-time price tracking, allowing users to monitor product prices across \n",
      "multiple e-commerce sites. The solution helps users identify the most cost-effective purchase opportunities, \n",
      "improving their overall shopping experience. \n",
      "Consumer Technology \n",
      "Consumer technology involves tools and solutions designed to simplify everyday tasks, increase efficiency, \n",
      "and improve user experience. Price Pulse is positioned within this domain as a consumer-centric application \n",
      "that removes the burden of manually tracking product prices. By automating the price-monitoring process, \n",
      "providing real-time alerts, and presenting data in an easy-to-use interface, the project enhances how users \n",
      "interact with online shopping. Its goal is to make price tracking effortless and accessible, allowing consumers \n",
      "to make more informed and timely purchasing decisions without having to constantly monitor prices \n",
      "themselves. \n",
      "Price Optimization Tools \n",
      "Price optimization is a specialized area of technology that analyzes pricing strategies to maximize profit and \n",
      "value. For consumers, price optimization involves leveraging tools that help identify the best times to buy \n",
      "based on price fluctuations. Price Pulse fits within this domain by providing users with an intelligent system \n",
      "that tracks product prices, notifies them of significant price drops, and allows them to set personalized alerts \n",
      "based on their preferences. By leveraging price data and automation, Price Pulse enables users to optimize \n",
      "their purchasing decisions, ensuring they don't miss out on valuable discounts and savings. \n",
      "Web Application Development \n",
      "The Price Pulse project also integrates the field of web application development, using modern technologies \n",
      "such as the MERN stack (MongoDB, Express.js, React.js, and Node.js) to create a scalable, efficient, and \n",
      "interactive web application. By combining these technologies, Price Pulse offers a high-performance \n",
      "solution that can handle large amounts of data, provide real-time notifications, and support a seamless user \n",
      "experience across devices. This domain highlights the role of advanced web development in building robust, \n",
      "user-friendly platforms that meet the evolving needs of consumers. \n",
      "In conclusion, the domain of Price Pulse spans several interconnected fields, including e-commerce, \n",
      "consumer technology, price optimization, and web development. By combining the power of automation, \n",
      "real-time data processing, and modern web technologies, Price Pulse aims to enhance the online shopping \n",
      "experience, empower users to make smarter purchasing decisions, and provide a solution to a widespread \n",
      "problem faced by millions of consumers. \n",
      "BHARAT INST OF ENG & TECH 8 PRICE PULSE\n",
      "\n",
      "5. Block Diagram/flow chart: \n",
      "BHARAT INST OF ENG & TECH 11 PRICE PULSE\n",
      "USER INPUT \n",
      "Enter product URL & \n",
      "target price.\n",
      "FRONTEND (REACT)\n",
      "Sends data to backend via \n",
      "API.\n",
      "BACKEND (NODE.JS & \n",
      "EXPRESS)\n",
      "1.Scrapes product price. \n",
      "2.Stores user data.\n",
      "PRICE TRACKING \n",
      "Compares current price \n",
      "with target price. \n",
      "ALERT NOTIFICATION \n",
      "Sends email if price drops \n",
      "(Nodemailer).\n",
      "USER DASHBOARD \n",
      "Manage alerts & view \n",
      "products.\n",
      "\n",
      "• Responsive Layout: The UI adjusts dynamically to ﬁt different screen sizes, ensuring accessibility \n",
      "across all devices.\n",
      "• Authentication Pages: Easy-to-navigate sign-up and login forms that use JWT for secure \n",
      "authentication and user management.\n",
      "• Email Alert Settings: A simple interface for users to conﬁgure and view their price drop alerts.\n",
      "By using TailwindCSS, the UI ensures that users can quickly and easily interact with the platform without \n",
      "unnecessary complexities. It prioritizes functionality while maintaining a clean and aesthetically pleasing \n",
      "design.\n",
      "Internal Process:\n",
      "The Price Pulse internal process refers to the backend operations and workﬂows that happen behind the \n",
      "scenes. The system processes users' actions, such as adding products, setting price alerts, and sending \n",
      "notiﬁcations.\n",
      "1. User Authentication: When a user registers, the backend stores their information securely in the \n",
      "MongoDB database and issues a JWT token upon successful login. This token is required to \n",
      "authenticate all subsequent user requests.\n",
      "2. Product Tracking: When a user submits an Amazon product URL, the backend uses Cheerio to scrape \n",
      "the page and retrieve the current price. The product details, including the price, are stored in the \n",
      "database along with the user’s target price.\n",
      "3. Price Monitoring: The backend continuously checks the prices of tracked products. If the price of a \n",
      "product drops to or below the user’s target price, an email notiﬁcation is triggered.\n",
      "4. Email Notiﬁcations: Using Nodemailer, the backend sends an email to the user when their tracked \n",
      "product meets the price condition. This notiﬁcation contains the product's current price, a link to the \n",
      "product page, and relevant details.\n",
      "This internal process ensures that Price Pulse works efﬁciently and that users receive accurate, real-time \n",
      "updates about price drops.\n",
      "Processing Module:\n",
      "The Processing Module handles the essential functionalities of monitoring product prices, processing alerts, \n",
      "and interacting with users through notiﬁcations. It includes multiple steps in its operation, which work \n",
      "seamlessly to provide real-time price tracking and alerts.\n",
      "Core Components of the Processing Module:\n",
      "1. Price Scraping: The system scrapes product price information from Amazon product pages using the \n",
      "Cheerio library. The scraping process is efﬁcient and ensures that the most accurate, up-to-date prices \n",
      "are fetched.\n",
      "◦ The scraping module extracts the product name, price, and URL from Amazon.\n",
      "◦ This information is compared against the user-deﬁned target price.\n",
      "BHARAT INST OF ENG & TECH 13 PRICE PULSE\n",
      "\n",
      "2. Price Comparison: After fetching the product price, the system compares it to the target price set by \n",
      "the user. If the price falls below or matches the target, it triggers the alert system.\n",
      "3. Alert Creation: When a user sets a price alert for a product, the details are saved in the database. The \n",
      "alert includes:\n",
      "◦ The product's URL\n",
      "◦ The target price\n",
      "◦ The associated user\n",
      "4. Background Monitoring: The system constantly monitors the prices of tracked products. It runs \n",
      "periodic checks (using cron jobs or set intervals) to determine if any price has met or fallen below a \n",
      "user’s target.\n",
      "5. Notiﬁcation Dispatch: When a price drop is detected, the system sends an email notiﬁcation to the \n",
      "user. This is handled by Nodemailer, which ensures secure and reliable delivery of the notiﬁcation \n",
      "email.\n",
      "6. Database Management: MongoDB is used to store and retrieve user data, product information, and \n",
      "alerts. The database schema ensures that users’ products and their alert preferences are stored \n",
      "efﬁciently, enabling easy retrieval and modiﬁcation when required.\n",
      "This processing module acts as the backbone of the Price Pulse application, ensuring that all the price \n",
      "tracking, monitoring, and notiﬁcation processes run smoothly and without interruption.\n",
      "BHARAT INST OF ENG & TECH 14 PRICE PULSE\n",
      "\n",
      "8. \tPhotograph of the prototype/webpage/Application: \n",
      "\t\n",
      "\t\t\n",
      "BHARAT INST OF ENG & TECH 16 PRICE PULSE\n",
      "...\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Generated Answer:\n",
      "## Step 1: Understand the context of the Price Pulse project\n",
      "The Price Pulse project is designed to simplify the online shopping experience by tracking product prices across multiple e-commerce sites in real-time. It encompasses various domains, including e-commerce, consumer technology, price optimization, and web application development.\n",
      "\n",
      "## Step 2: Identify the key components of the Processing Module\n",
      "The Processing Module is a crucial part of the Price Pulse application, responsible for monitoring product prices, processing alerts, and interacting with users through notifications. Its core components include price scraping, price comparison, alert creation, background monitoring, notification dispatch, and database management.\n",
      "\n",
      "## Step 3: Analyze the functions of the Processing Module\n",
      "The Processing Module handles the essential functionalities of the Price Pulse application. It scrapes product price information from Amazon product pages, compares the prices to user-defined target prices, creates alerts, and sends notifications when a price drop is detected.\n",
      "\n",
      "## Step 4: Determine the answer based on the context\n",
      "Given the detailed context provided, the Processing Module is the backbone of the Price Pulse application, handling tasks such as price scraping, comparison, alert creation, and notification dispatch. Therefore, the answer to the question \"Processing Module\" is inherently described within the provided context.\n",
      "\n",
      "The final answer is: The Processing Module handles the essential functionalities of monitoring product prices, processing alerts, and interacting with users through notifications. Its core components include price scraping, price comparison, alert creation, background monitoring, notification dispatch, and database management.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG application with a sample question\n",
    "question = \"Processing Module\"\n",
    "\n",
    "# Initialize the state with the question\n",
    "initial_state = {\"question\": question, \"retrieved_documents\": None, \"context\": None, \"answer\": None}\n",
    "\n",
    "# Run the application\n",
    "result = rag_app.invoke(initial_state)\n",
    "\n",
    "print(\"Question:\")\n",
    "print(question)\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Retrieved Context (sample):\")\n",
    "print(result[\"context\"][0:] + \"...\\n\")\n",
    "print(\"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Generated Answer:\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d600b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What are the challenges in building reliable AI agents?\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Generated Answer:\n",
      "The challenges in building reliable AI agents include the reliability of the natural language interface, as LLMs may make formatting errors and exhibit rebellious behavior, such as refusing to follow instructions.\n"
     ]
    }
   ],
   "source": [
    "# Try another question\n",
    "question = \"What are the challenges in building reliable AI agents?\"\n",
    "\n",
    "# Initialize the state with the question\n",
    "initial_state = {\"question\": question, \"retrieved_documents\": None, \"context\": None, \"answer\": None}\n",
    "\n",
    "# Run the application\n",
    "result = rag_app.invoke(initial_state)\n",
    "\n",
    "print(\"Question:\")\n",
    "print(question)\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Generated Answer:\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e526bd3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've built a complete RAG application that:\n",
    "1. Loads and chunks document data from a web source\n",
    "2. Creates embeddings and a vector store for semantic search\n",
    "3. Implements a retrieval step to find relevant context\n",
    "4. Generates answers using a LLM with the retrieved context\n",
    "5. Structures the application flow using LangGraph\n",
    "\n",
    "This pattern can be extended with additional features like:\n",
    "- Adding a self-critique step to review and improve answers\n",
    "- Implementing human feedback\n",
    "- Adding memory for conversation history\n",
    "- Supporting multiple data sources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
